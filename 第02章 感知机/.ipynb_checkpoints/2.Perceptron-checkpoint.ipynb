{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2章 感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．感知机是根据输入实例的特征向量$x$对其进行二类分类的线性分类模型：\n",
    "\n",
    "$$\n",
    "f(x)=\\operatorname{sign}(w \\cdot x+b)\n",
    "$$\n",
    "\n",
    "感知机模型对应于输入空间（特征空间）中的分离超平面$w \\cdot x+b=0$。\n",
    "\n",
    "2．感知机学习的策略是极小化损失函数：\n",
    "\n",
    "$$\n",
    "\\min _{w, b} L(w, b)=-\\sum_{x_{i} \\in M} y_{i}\\left(w \\cdot x_{i}+b\\right)\n",
    "$$\n",
    "\n",
    "损失函数对应于误分类点到分离超平面的总距离。\n",
    "\n",
    "3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。\n",
    " \n",
    "4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数$k$满足不等式：\n",
    "\n",
    "$$\n",
    "k \\leqslant\\left(\\frac{R}{\\gamma}\\right)^{2}\n",
    "$$\n",
    "\n",
    "当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二分类模型\n",
    "$f(x) = sign(w\\cdot x + b)$\n",
    "\n",
    "$\\operatorname{sign}(x)=\\left\\{\\begin{array}{ll}{+1,} & {x \\geqslant 0} \\\\ {-1,} & {x<0}\\end{array}\\right.$\n",
    "\n",
    "给定训练集：\n",
    "\n",
    "$T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}$\n",
    "\n",
    "定义感知机的损失函数 \n",
    "\n",
    "$L(w, b)=-\\sum_{x_{i} \\in M} y_{i}\\left(w \\cdot x_{i}+b\\right)$\n",
    "\n",
    "---\n",
    "#### 算法\n",
    "\n",
    "随即梯度下降法 Stochastic Gradient Descent\n",
    "\n",
    "随机抽取一个误分类点使其梯度下降。\n",
    "\n",
    "$w = w + \\eta y_{i}x_{i}$\n",
    "\n",
    "$b = b + \\eta y_{i}$\n",
    "\n",
    "当实例点被误分类，即位于分离超平面的错误侧，则调整$w$, $b$的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【1】算法实现-原始形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../images/感知机原始算法.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [0, 0] b: 0\n",
      "w: [3, 3] b: 1\n",
      "w: [2, 2] b: 0\n",
      "w: [1, 1] b: -1\n",
      "w: [0, 0] b: -2\n",
      "w: [3, 3] b: -1\n",
      "w: [2, 2] b: -2\n",
      "[1, 1] -3\n"
     ]
    }
   ],
   "source": [
    "from numpy import *  \n",
    "import operator\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# create a dataset which contains 3 samples with 2 classes  \n",
    "def createDataSet():  \n",
    "    # create a matrix: each row as a sample  \n",
    "    group = array([[3,3], [4,3], [1,1]])  \n",
    "    labels = [1, 1, -1] # four samples and two classes  \n",
    "    return group, labels\n",
    "\n",
    "#classify using perceptron\n",
    "def perceptronClassify(trainGroup,trainLabels):\n",
    "    global w, b\n",
    "    isFind = False  #the flag of find the best w and b\n",
    "    numSamples = trainGroup.shape[0]\n",
    "    mLenth = trainGroup.shape[1]\n",
    "    w = [0]*mLenth\n",
    "    b = 0\n",
    "    while(not isFind):\n",
    "        for i in range(numSamples):\n",
    "            if cal(trainGroup[i],trainLabels[i]) <= 0:\n",
    "                print('w:', w, 'b:', b)\n",
    "                update(trainGroup[i],trainLabels[i])\n",
    "                break    #end for loop\n",
    "            elif i == numSamples-1:\n",
    "                print(w, b)\n",
    "                isFind = True   #end while loop\n",
    "\n",
    "\n",
    "def cal(row,trainLabel):\n",
    "    global w, b\n",
    "    res = 0\n",
    "    for i in range(len(row)):\n",
    "        res += row[i] * w[i]\n",
    "    res += b\n",
    "    res *= trainLabel\n",
    "    return res\n",
    "def update(row,trainLabel):\n",
    "    global w, b\n",
    "    for i in range(len(row)):\n",
    "        w[i] += trainLabel * row[i]\n",
    "    b += trainLabel\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    g,l = createDataSet()\n",
    "    perceptronClassify(g,l)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【2】算法实现-对偶形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../images/感知机算法对偶形式.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] 0\n",
      "[3 3] 1\n",
      "[2 2] 0\n",
      "[1 1] -1\n",
      "[0 0] -2\n",
      "[3 3] -1\n",
      "[2 2] -2\n",
      "[1 1] -3\n"
     ]
    }
   ],
   "source": [
    "from numpy import *  \n",
    "import operator\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# create a dataset which contains 3 samples with 2 classes  \n",
    "def createDataSet():  \n",
    "    # create a matrix: each row as a sample  \n",
    "    group = array([[3,3], [4,3], [1,1]])  \n",
    "    labels = [1, 1, -1] # four samples and two classes  \n",
    "    return group, labels\n",
    "\n",
    "#classify using DualPerception\n",
    "def dualPerceptionClassify(trainGroup,trainLabels):\n",
    "    global a,b\n",
    "    isFind = False\n",
    "    numSamples = trainGroup.shape[0]\n",
    "    #mLenth = trainGroup.shape[1]\n",
    "    a = [0]*numSamples\n",
    "    b = 0\n",
    "    gMatrix = cal_gram(trainGroup)\n",
    "    while(not isFind):\n",
    "        for i in range(numSamples):\n",
    "            if cal(gMatrix,trainLabels,i) <= 0:\n",
    "                cal_wb(trainGroup,trainLabels)\n",
    "                update(i,trainLabels[i])\n",
    "                break\n",
    "            elif i == numSamples-1:\n",
    "                cal_wb(trainGroup,trainLabels)\n",
    "                isFind = True\n",
    "    \n",
    "\n",
    "# caculate the Gram matrix\n",
    "def cal_gram(group):\n",
    "    mLenth = group.shape[0]\n",
    "    gMatrix = zeros((mLenth,mLenth))\n",
    "    for i in range(mLenth):\n",
    "        for j in range(mLenth):\n",
    "            gMatrix[i][j] =  dot(group[i],group[j])\n",
    "    return gMatrix\n",
    "\n",
    "def update(i,trainLabel):\n",
    "    global a,b\n",
    "    a[i] += 1\n",
    "    b += trainLabel\n",
    "\n",
    "def cal(gMatrix,trainLabels,key):\n",
    "    global a,b\n",
    "    res = 0\n",
    "    for i in range(len(trainLabels)):\n",
    "        res += a[i]*trainLabels[i]*gMatrix[key][i]\n",
    "    res = (res + b)*trainLabels[key]\n",
    "    return res\n",
    "\n",
    "#caculator w and b,then print it\n",
    "def cal_wb(group,labels):\n",
    "    global a,b\n",
    "    w=[0]*(group.shape[1])\n",
    "    h = 0\n",
    "    for i in range(len(labels)):\n",
    "        h +=a[i]*labels[i]\n",
    "        w +=a[i]*labels[i]*group[i]\n",
    "    print(w,h)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    g, l = createDataSet()\n",
    "    dualPerceptionClassify(g, l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
